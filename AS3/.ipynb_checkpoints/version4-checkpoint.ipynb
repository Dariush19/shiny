{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and install necessary Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import sys\n",
    "#!{sys.executable} -m pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-usable functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Print columns with null value.\n",
    "'''\n",
    "def get_cols_with_null(df):\n",
    "    # Get a list containing each column and number of null values in each column\n",
    "    col_list = []\n",
    "    x = len(df) - df.count()\n",
    "    for i in range(0, len(all_columns)):\n",
    "        if x[i] > 0:\n",
    "            col_list.append(str(all_columns[i]))\n",
    "            \n",
    "    return col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Transpose the count values for each of the day columns (75 of them) into a a 3 column dataframe containing the id, day value and the count for the day.\n",
    "'''\n",
    "def trans_data(input_df, date_col_names):\n",
    "    col_id =   []\n",
    "    col_date = []\n",
    "    col_cnt =  []\n",
    "    ncol = len(date_col_names)\n",
    "    for i in range(0, len(input_df)):\n",
    "        for j in range(0, ncol-1):\n",
    "          col_id.append(input_df.iloc[i][75])\n",
    "          col_date.append(date_col_names[j])\n",
    "          col_cnt.append(input_df.iloc[i][j])\n",
    "\n",
    "    the_dict = {'id':col_id,'the_date':col_date, 'the_count':col_cnt}\n",
    "    out_df = pd.DataFrame(the_dict) \n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Generate consistent column names for each day that could be later used as valid dates. \n",
    "The column names for dates is used for all data sets.\n",
    "'''\n",
    "start_date = datetime.datetime(2020, 1, 22)\n",
    "end_date = datetime.datetime(2020, 4, 5)\n",
    "oneDay = datetime.timedelta(days=1)\n",
    "\n",
    "# Generate column names for days to cover\n",
    "date_col_names = []\n",
    "while start_date <= end_date:\n",
    "    col_name = \"{}-{}-{}\".format(start_date.day, start_date.month, start_date.year)\n",
    "    start_date += oneDay\n",
    "    date_col_names.append(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Read the 3 data sets into separate dataframes and perform initial data wrangling\n",
    "'''\n",
    "c1 = pd.read_csv(\"E:\\\\Personal_Files\\\\Dariush\\monash\\\\visual\\\\AS3\\\\new\\\\time_series_covid19_confirmed_global.csv\")\n",
    "#c1 = pd.read_csv(\"E:\\\\Personal_Files\\\\Dariush\\monash\\\\visual\\\\AS3\\\\new\\\\reduced.csv\")\n",
    "d1 = pd.read_csv(\"E:\\\\Personal_Files\\\\Dariush\\monash\\\\visual\\\\AS3\\\\new\\\\time_series_covid19_deaths_global.csv\")\n",
    "r1 = pd.read_csv(\"E:\\\\Personal_Files\\\\Dariush\\monash\\\\visual\\\\AS3\\\\new\\\\time_series_covid19_recovered_global.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before update: Names of columns with null values:  ['State']\n",
      "After update: Names of columns with null values:  []\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1. Rename date columns\n",
    "2. identify columns with a null vale.\n",
    "3. State happens to be the only one; Replace its missing values with the name of the country;\n",
    "4. Add an 'id' column with a sequential number (equalling the index.\n",
    "'''\n",
    "all_columns = ['State', 'Country', 'Lat', 'Long'] + date_col_names\n",
    "c1.columns = all_columns\n",
    "print(\"Before update: Names of columns with null values: \", get_cols_with_null(c1))\n",
    "c1.State.fillna(c1.Country, inplace=True)\n",
    "print(\"After update: Names of columns with null values: \", get_cols_with_null(c1))\n",
    "c1['id'] = c1.index "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create two subsets of the list. One that includes all columns to and including longitude, and another that includes from the first date column to id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "5. Create two subsets of the list. \n",
    "One that includes all columns to and including longitude, \n",
    "and another that includes from the first date column to id.\n",
    "'''\n",
    "c11 = pd.concat((c1.loc[:, :'Long'], c1.loc[:, 'id']), axis=1)\n",
    "c12 = c1.loc[:, '22-1-2020':'id']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "6. Rename the columns as we want to make room for same column names to hold the increments. \n",
    "Figures/counts as given are accummulative. \n",
    "We need increments to be able to perform aggregation at the time of visualization.\n",
    "'''\n",
    "for ix2 in range(0, len(date_col_names)): \n",
    "    col_name = 'X-' + date_col_names[ix2]\n",
    "    c12[col_name] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "7. Extract increments by subtracting the next day from its previous day.\n",
    "'''\n",
    "for ix1 in range(0, len(c12)):\n",
    "    for ix2 in range(0, len(date_col_names)-1): \n",
    "        new_col = 'X-' + date_col_names[ix2+1]\n",
    "        delta = c12.iloc[ix1][ix2+1] - c12.iloc[ix1][ix2]\n",
    "        new_col_no = len(date_col_names) + ix2\n",
    "        c12.loc[ix1].at[new_col] = delta\n",
    "        #print(new_col, c12.iloc[ix1][ix2+1], c12.iloc[ix1][ix2], delta)\n",
    "        \n",
    "# c12.to_csv (r'E:\\Personal_Files\\Dariush\\monash\\visual\\AS3\\\\new\\temp_condf.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "8. Now, rename the columns back to what they were.\n",
    "'''\n",
    "last_day = 'X-' + date_col_names[len(date_col_names)-1]\n",
    "c12a = c12.loc[:, 'id':last_day]\n",
    "\n",
    "for ix in range(0, len(date_col_names)): \n",
    "    old_col_name = 'X-' + date_col_names[ix]\n",
    "    new_col_name = date_col_names[ix]\n",
    "    c12a.rename(columns={old_col_name:new_col_name}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Transpose daye columns to individual rows\n",
    "7. Rename generic column names to appropriate columnn names\n",
    "8. Perform cartesian join the two data frames created from step 5 and 7 above to reunite the data. Join is on the id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: The number of rows in the resulting data frame matches the number of rows in the original data frame by the number of data\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "9. Transpose daye columns to individual rows\n",
    "10. Rename generic column names to appropriate columnn names\n",
    "11. Perform cartesian join the two data frames created from step 5 and 7 above to reunite the data. Join is on the id.\n",
    "'''\n",
    "c12h_frame = trans_data(c12, date_col_names)\n",
    "c12h_frame = c12h_frame.rename(columns={'the_date': 'confirmed_date', 'the_count': 'confirmed_count'})\n",
    "df_confirmed = pd.merge(c11, c12h_frame,on='id')\n",
    "if len(df_confirmed) == len(c1) * (len(date_col_names) - 1):\n",
    "   print(\"Success: The number of rows in the resulting data frame matches the number of rows \\\n",
    "in the original data frame by the number of data\")\n",
    "else:\n",
    "   print(\"Something wrong: The number of rows in the resulting data frame does not matches with \\\n",
    "number of rows in the original data frame by the number of data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform same data wrangling for second data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before update: Names of columns with null values:  ['State']\n",
      "After update: Names of columns with null values:  []\n"
     ]
    }
   ],
   "source": [
    "d1.columns = all_columns\n",
    "print(\"Before update: Names of columns with null values: \", get_cols_with_null(d1))\n",
    "d1.State.fillna(d1.Country, inplace=True)\n",
    "print(\"After update: Names of columns with null values: \", get_cols_with_null(d1))\n",
    "d1['id'] = d1.index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: The number of rows in the resulting data frame matches the number of rows in the original data frame by the number of data\n"
     ]
    }
   ],
   "source": [
    "d11 = pd.concat((d1.loc[:, :'Long'], d1.loc[:, 'id']), axis=1)\n",
    "d12 = d1.loc[:, '22-1-2020':'id']\n",
    "\n",
    "d12h_frame = trans_data(d12, date_col_names)\n",
    "d12h_frame = d12h_frame.rename(columns={'the_date': 'death_date', 'the_count': 'death_count'})\n",
    "df_deaths = pd.merge(d11, d12h_frame,on='id')\n",
    "if len(df_confirmed) == len(d1) * (len(date_col_names) - 1):\n",
    "   print(\"Success: The number of rows in the resulting data frame matches the number of rows \\\n",
    "in the original data frame by the number of data\")\n",
    "else:\n",
    "   print(\"Something wrong: The number of rows in the resulting data frame does not matches with \\\n",
    "number of rows in the original data frame by the number of data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport plotly.express as px\\n\\nfig = px.bar(df_deaths, x='death_date', y='death_count',\\n              color='death_date',\\n             labels={'Confirmed Cases':'Corona Stats'}, height=400)\\nfig.show()\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.bar(df_deaths, x='death_date', y='death_count',\n",
    "              color='death_date',\n",
    "             labels={'Confirmed Cases':'Corona Stats'}, height=400)\n",
    "fig.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform same data wrangling process for recovered data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before update: Names of columns with null values:  ['State']\n",
      "After update: Names of columns with null values:  []\n"
     ]
    }
   ],
   "source": [
    "r1.columns = all_columns\n",
    "print(\"Before update: Names of columns with null values: \", get_cols_with_null(r1))\n",
    "r1.State.fillna(r1.Country, inplace=True)\n",
    "print(\"After update: Names of columns with null values: \", get_cols_with_null(r1))\n",
    "r1['id'] = r1.index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: The number of rows in the resulting data frame matches the number of rows in the original data frame by the number of data\n"
     ]
    }
   ],
   "source": [
    "r11 = pd.concat((r1.loc[:, :'Long'], r1.loc[:, 'id']), axis=1)\n",
    "r12 = r1.loc[:, '22-1-2020':'id']\n",
    "\n",
    "r12h_frame = trans_data(r12, date_col_names)\n",
    "r12h_frame = r12h_frame.rename(columns={'the_date': 'recovered_date', 'the_count': 'recovered_count'})\n",
    "df_recovered = pd.merge(r11, r12h_frame,on='id')\n",
    "if len(df_recovered) == len(r1) * (len(date_col_names) - 1):\n",
    "   print(\"Success: The number of rows in the resulting data frame matches the number of rows \\\n",
    "in the original data frame by the number of data\")\n",
    "else:\n",
    "   print(\"Something wrong: The number of rows in the resulting data frame does not matches with \\\n",
    "number of rows in the original data frame by the number of data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport plotly.express as px\\n\\nfig = px.bar(df_recovered, x='recovered_date', y='recovered_count',\\n              color='recovered_date',\\n             labels={'Recovered Cases':'Corona Stats'}, height=400)\\nfig.show()\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.bar(df_recovered, x='recovered_date', y='recovered_count',\n",
    "              color='recovered_date',\n",
    "             labels={'Recovered Cases':'Corona Stats'}, height=400)\n",
    "fig.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confirmed_death = pd.merge(df_confirmed, df_deaths,  how='left', left_on=['Country', 'State', 'confirmed_date'], right_on=['Country', 'State', 'death_date'])\n",
    "df_confirmed_death_recovered = pd.merge(df_confirmed_death, df_recovered, how='left', left_on=['Country', 'State', 'confirmed_date'], right_on=['Country', 'State', 'recovered_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19388"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_confirmed_death_recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_confirmed_death_recovered[['Country', 'State', 'Long', 'Lat', 'confirmed_date', 'confirmed_count', 'death_count', 'recovered_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Long</th>\n",
       "      <th>Lat</th>\n",
       "      <th>confirmed_date</th>\n",
       "      <th>confirmed_count</th>\n",
       "      <th>death_count</th>\n",
       "      <th>recovered_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>65.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>22-1-2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>65.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>23-1-2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>65.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24-1-2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>65.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>25-1-2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>65.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>26-1-2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>65.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27-1-2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>65.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>28-1-2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>65.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>29-1-2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>65.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>30-1-2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>65.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>31-1-2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country        State  Long   Lat confirmed_date  confirmed_count  \\\n",
       "0  Afghanistan  Afghanistan  65.0  33.0      22-1-2020                0   \n",
       "1  Afghanistan  Afghanistan  65.0  33.0      23-1-2020                0   \n",
       "2  Afghanistan  Afghanistan  65.0  33.0      24-1-2020                0   \n",
       "3  Afghanistan  Afghanistan  65.0  33.0      25-1-2020                0   \n",
       "4  Afghanistan  Afghanistan  65.0  33.0      26-1-2020                0   \n",
       "5  Afghanistan  Afghanistan  65.0  33.0      27-1-2020                0   \n",
       "6  Afghanistan  Afghanistan  65.0  33.0      28-1-2020                0   \n",
       "7  Afghanistan  Afghanistan  65.0  33.0      29-1-2020                0   \n",
       "8  Afghanistan  Afghanistan  65.0  33.0      30-1-2020                0   \n",
       "9  Afghanistan  Afghanistan  65.0  33.0      31-1-2020                0   \n",
       "\n",
       "   death_count  recovered_count  \n",
       "0            0              0.0  \n",
       "1            0              0.0  \n",
       "2            0              0.0  \n",
       "3            0              0.0  \n",
       "4            0              0.0  \n",
       "5            0              0.0  \n",
       "6            0              0.0  \n",
       "7            0              0.0  \n",
       "8            0              0.0  \n",
       "9            0              0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv (r'E:\\Personal_Files\\Dariush\\monash\\visual\\AS3\\\\new\\time_series_covid19_ALL_global.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
